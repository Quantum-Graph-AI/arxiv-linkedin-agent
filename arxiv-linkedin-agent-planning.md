# ArxivAgent: Sistema Multi-Agente para Curadoria e DisseminaÃ§Ã£o de Papers de IA

## VisÃ£o Geral do Projeto

O ArxivAgent Ã© um sistema autÃ´nomo multi-agente construÃ­do inteiramente em Rust que automatiza o ciclo completo de descoberta, anÃ¡lise e publicaÃ§Ã£o de conteÃºdo sobre papers de IA no LinkedIn. O sistema opera como uma entidade cognitiva distribuÃ­da em agentes especializados, coordenados por algoritmos de consenso entre dois LLMs (Groq e OpenRouter), garantindo qualidade de anÃ¡lise enquanto respeita limites gratuitos de API.

A arquitetura foi projetada para execuÃ§Ã£o serverless via GitHub Actions, tratando o repositÃ³rio como infraestrutura e utilizando DuckDB + LanceDB para persistÃªncia GitOps. O diferencial estÃ¡ na engenharia de contexto inspirada no Claude-Flow, permitindo memÃ³ria de longo prazo e raciocÃ­nio contextualizado sobre papers extensos.

---

## 1. Arquitetura de Alto NÃ­vel

### 1.1 Topologia Multi-Agentes

O sistema Ã© composto por cinco agentes especializados que colaboram de forma orquestrada:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           ARXIV AGENT ORCHESTRATOR                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚    SCOUT     â”‚â”€â”€â”€â–¶â”‚   ANALYST    â”‚â”€â”€â”€â–¶â”‚    SCRIBE    â”‚                  â”‚
â”‚  â”‚  (IngestÃ£o)  â”‚    â”‚  (Cognitivo) â”‚    â”‚  (Criativo)  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚         â”‚                   â”‚                   â”‚                           â”‚
â”‚         â”‚                   â–¼                   â”‚                           â”‚
â”‚         â”‚           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚                           â”‚
â”‚         â”‚           â”‚   CONSENSUS  â”‚            â”‚                           â”‚
â”‚         â”‚           â”‚   ENGINE     â”‚            â”‚                           â”‚
â”‚         â”‚           â”‚  (PBFT/2LLM) â”‚            â”‚                           â”‚
â”‚         â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚                           â”‚
â”‚         â”‚                   â”‚                   â”‚                           â”‚
â”‚         â–¼                   â–¼                   â–¼                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚                    MEMORY LAYER (Claude-Flow)                    â”‚       â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚       â”‚
â”‚  â”‚  â”‚   DuckDB    â”‚  â”‚   LanceDB   â”‚  â”‚   Context Window Mgr    â”‚  â”‚       â”‚
â”‚  â”‚  â”‚ (Relacional)â”‚  â”‚  (Vetorial) â”‚  â”‚ (Chunking + Hierarchy)  â”‚  â”‚       â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚         â”‚                                       â”‚                           â”‚
â”‚         â–¼                                       â–¼                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚   GUARDIAN   â”‚                        â”‚   LIAISON    â”‚                  â”‚
â”‚  â”‚  (Shabbat)   â”‚                        â”‚  (Telegram)  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                 â”‚                           â”‚
â”‚                                                 â–¼                           â”‚
â”‚                                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚                                          â”‚   LinkedIn   â”‚                  â”‚
â”‚                                          â”‚   Publisher  â”‚                  â”‚
â”‚                                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 DescriÃ§Ã£o dos Agentes

**Scout (Agente de IngestÃ£o)**
ResponsÃ¡vel pela varredura diÃ¡ria do Arxiv, aplicando filtros heurÃ­sticos (regex) e semÃ¢nticos (LLM rÃ¡pido) para identificar papers relevantes nos tÃ³picos configurados. Detecta sinais de trabalhos disruptivos como AlphaEvolve e Absolute Zero atravÃ©s de padrÃµes especÃ­ficos.

**Analyst (Agente Cognitivo)**
O cÃ©rebro do sistema. Processa papers completos utilizando engenharia de contexto avanÃ§ada para extrair insights de segunda ordem. Opera em cooperaÃ§Ã£o com o Consensus Engine para validar anÃ¡lises.

**Scribe (Agente Criativo)**
Especialista em copywriting para LinkedIn. Utiliza Few-Shot Learning com posts anteriores do usuÃ¡rio para mimetizar estilo. Gera mÃºltiplas variaÃ§Ãµes para A/B testing implÃ­cito.

**Guardian (Agente de Conformidade)**
MÃ³dulo determinÃ­stico que calcula horÃ¡rios de Shabbat usando astronomia precisa (crate `sunrise`) e bloqueia publicaÃ§Ãµes durante janelas proibidas (sexta ao pÃ´r do sol atÃ© sÃ¡bado ao pÃ´r do sol).

**Liaison (Agente de Interface)**
Gerencia comunicaÃ§Ã£o bidirecional com o humano via Telegram. Envia drafts para aprovaÃ§Ã£o, recebe feedback, e propaga decisÃµes de volta ao sistema.

---

## 2. Fluxo de Dados e Pipeline

### 2.1 Pipeline Principal

```
                                    PIPELINE DIÃRIO
                                    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Arxiv  â”‚â”€â”€â”€â”€â–¶â”‚  Scout  â”‚â”€â”€â”€â”€â–¶â”‚ Analyst â”‚â”€â”€â”€â”€â–¶â”‚ Scribe  â”‚â”€â”€â”€â”€â–¶â”‚Telegram â”‚
    â”‚   API   â”‚     â”‚ Filter  â”‚     â”‚ Process â”‚     â”‚ Generateâ”‚     â”‚ Approvalâ”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚               â”‚               â”‚               â”‚
                          â–¼               â–¼               â–¼               â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                    DuckDB / LanceDB                     â”‚
                    â”‚   - papers_processed    - paper_embeddings             â”‚
                    â”‚   - posts_generated     - style_examples               â”‚
                    â”‚   - approval_history    - insights_knowledge           â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                              â”‚
                                              â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                 APPROVAL WORKFLOW                       â”‚
                    â”‚                                                         â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   APPROVED   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
                    â”‚  â”‚ Telegram â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¶â”‚  Guardian â”‚â”€â”€â–¶ LinkedIn   â”‚
                    â”‚  â”‚ Response â”‚              â”‚   Check   â”‚               â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
                    â”‚       â”‚                                                 â”‚
                    â”‚       â”‚ REJECTED                                        â”‚
                    â”‚       â–¼                                                 â”‚
                    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                           â”‚
                    â”‚  â”‚  Scribe  â”‚â—€â”€â”€â”€ Feedback Loop                         â”‚
                    â”‚  â”‚ Revise   â”‚                                           â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                           â”‚
                    â”‚                                                         â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 Mecanismo de Consenso entre LLMs

O sistema utiliza um protocolo inspirado em PBFT (Practical Byzantine Fault Tolerance) simplificado para decisÃµes crÃ­ticas entre os dois LLMs:

```
                         CONSENSUS PROTOCOL
                         
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
    â”‚  â”‚    Groq     â”‚         â”‚ OpenRouter  â”‚                       â”‚
    â”‚  â”‚ gpt-oss-120bâ”‚         â”‚ grok-4.1    â”‚                       â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                       â”‚
    â”‚         â”‚                       â”‚                               â”‚
    â”‚         â–¼                       â–¼                               â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                       â”‚
    â”‚  â”‚  Proposal   â”‚         â”‚  Proposal   â”‚                       â”‚
    â”‚  â”‚  (Draft A)  â”‚         â”‚  (Draft B)  â”‚                       â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                       â”‚
    â”‚         â”‚                       â”‚                               â”‚
    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
    â”‚                     â–¼                                           â”‚
    â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
    â”‚              â”‚   COMPARE   â”‚                                    â”‚
    â”‚              â”‚   & MERGE   â”‚                                    â”‚
    â”‚              â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
    â”‚                     â”‚                                           â”‚
    â”‚         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
    â”‚         â–¼           â–¼           â–¼                               â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
    â”‚   â”‚ Agreement â”‚ â”‚ Partial   â”‚ â”‚ Conflict  â”‚                    â”‚
    â”‚   â”‚ (Use as-is)â”‚ â”‚(Merge)   â”‚ â”‚ (Re-vote) â”‚                    â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Regras do Consenso:**
1. Ambos LLMs recebem o mesmo contexto e prompt
2. Cada um gera sua proposta independente
3. As propostas sÃ£o comparadas por similaridade semÃ¢ntica
4. Se concordÃ¢ncia > 80%: aceita proposta com maior score interno
5. Se concordÃ¢ncia 50-80%: merge inteligente das melhores partes
6. Se concordÃ¢ncia < 50%: terceira rodada com contexto adicional

---

## 3. Engenharia de Contexto (Claude-Flow)

### 3.1 Arquitetura de MemÃ³ria HÃ­brida

O sistema implementa o paradigma Claude-Flow adaptado para Rust, combinando diferentes tipos de memÃ³ria:

```
                    HYBRID MEMORY ARCHITECTURE
                    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚                  EPISODIC MEMORY                        â”‚   â”‚
    â”‚  â”‚              (DuckDB: session_logs)                     â”‚   â”‚
    â”‚  â”‚                                                         â”‚   â”‚
    â”‚  â”‚  - Current session state                                â”‚   â”‚
    â”‚  â”‚  - Papers processed today                               â”‚   â”‚
    â”‚  â”‚  - API errors and retries                               â”‚   â”‚
    â”‚  â”‚  - Decisions made this run                              â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚                  SEMANTIC MEMORY                        â”‚   â”‚
    â”‚  â”‚             (LanceDB: paper_embeddings)                 â”‚   â”‚
    â”‚  â”‚                                                         â”‚   â”‚
    â”‚  â”‚  - Vector embeddings of all processed papers            â”‚   â”‚
    â”‚  â”‚  - Similarity search for deduplication                  â”‚   â”‚
    â”‚  â”‚  - Related work retrieval                               â”‚   â”‚
    â”‚  â”‚  - Style examples embeddings                            â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚                 REASONING BANK                          â”‚   â”‚
    â”‚  â”‚           (DuckDB: insights_knowledge)                  â”‚   â”‚
    â”‚  â”‚                                                         â”‚   â”‚
    â”‚  â”‚  - Paper â†’ Insight mappings                             â”‚   â”‚
    â”‚  â”‚  - User feedback (approved/rejected)                    â”‚   â”‚
    â”‚  â”‚  - Quality scores over time                             â”‚   â”‚
    â”‚  â”‚  - Learned preferences                                  â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚              CONTEXT WINDOW MANAGER                     â”‚   â”‚
    â”‚  â”‚                                                         â”‚   â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                 â”‚   â”‚
    â”‚  â”‚  â”‚Chunking â”‚  â”‚Hierarchyâ”‚  â”‚Priority â”‚                 â”‚   â”‚
    â”‚  â”‚  â”‚ Engine  â”‚  â”‚ Builder â”‚  â”‚ Queue   â”‚                 â”‚   â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                 â”‚   â”‚
    â”‚  â”‚                                                         â”‚   â”‚
    â”‚  â”‚  - Papers divididos em chunks de ~4K tokens             â”‚   â”‚
    â”‚  â”‚  - Hierarquia: Summary â†’ Section â†’ Detail               â”‚   â”‚
    â”‚  â”‚  - Retrieval dinÃ¢mico baseado na query                  â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 EstratÃ©gia para Papers Extensos (100+ pÃ¡ginas)

Para papers muito grandes, o sistema implementa processamento hierÃ¡rquico:

```
                    HIERARCHICAL PAPER PROCESSING
                    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                 â”‚
    â”‚  PAPER (200 pÃ¡ginas)                                           â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â–¼                                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
    â”‚  â”‚   LEVEL 0   â”‚  Full PDF extraction + structure detection    â”‚
    â”‚  â”‚  (Raw Text) â”‚  Identificar seÃ§Ãµes, figuras, tabelas         â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â–¼                                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
    â”‚  â”‚   LEVEL 1   â”‚  Resumo executivo de cada seÃ§Ã£o (~500 tokens) â”‚
    â”‚  â”‚  (Summaries)â”‚  Gerado por Groq (rÃ¡pido)                     â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â–¼                                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
    â”‚  â”‚   LEVEL 2   â”‚  AnÃ¡lise profunda das seÃ§Ãµes-chave            â”‚
    â”‚  â”‚  (Analysis) â”‚  Gerado por OpenRouter (raciocÃ­nio)           â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â–¼                                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
    â”‚  â”‚   LEVEL 3   â”‚  SÃ­ntese final + insights de 2Âª ordem         â”‚
    â”‚  â”‚ (Synthesis) â”‚  Consenso entre LLMs                          â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â–¼                                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚                POST SERIES PLANNING                      â”‚   â”‚
    â”‚  â”‚                                                          â”‚   â”‚
    â”‚  â”‚   Paper muito grande? â†’ Dividir em sÃ©rie de posts       â”‚   â”‚
    â”‚  â”‚                                                          â”‚   â”‚
    â”‚  â”‚   Post 1 (Pt 1): Problema e MotivaÃ§Ã£o                   â”‚   â”‚
    â”‚  â”‚   Post 2 (Pt 2): SoluÃ§Ã£o TÃ©cnica Principal              â”‚   â”‚
    â”‚  â”‚   Post 3 (Pt 3): Resultados e ImplicaÃ§Ãµes               â”‚   â”‚
    â”‚  â”‚   Post 4 (Pt N): ConexÃµes e Futuro                      â”‚   â”‚
    â”‚  â”‚                                                          â”‚   â”‚
    â”‚  â”‚   Cada post Ã© armazenado com series_id para tracking    â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Rate Limiting e Gerenciamento de APIs

### 4.1 Limites e EstratÃ©gia de Uso

```
                    RATE LIMIT MANAGEMENT
                    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                 â”‚
    â”‚  GROQ (openai/gpt-oss-120b)                                    â”‚
    â”‚  â”œâ”€â”€ RPM: 30 requests/minute                                   â”‚
    â”‚  â”œâ”€â”€ RPD: 1,000 requests/day                                   â”‚
    â”‚  â”œâ”€â”€ TPM: 8,000 tokens/minute                                  â”‚
    â”‚  â””â”€â”€ TPD: 200,000 tokens/day                                   â”‚
    â”‚                                                                 â”‚
    â”‚  USO PLANEJADO:                                                â”‚
    â”‚  â”œâ”€â”€ Filtragem inicial: ~50 papers Ã— 500 tokens = 25K tokens   â”‚
    â”‚  â”œâ”€â”€ AnÃ¡lise rÃ¡pida: ~10 papers Ã— 2K tokens = 20K tokens       â”‚
    â”‚  â”œâ”€â”€ Consenso: ~5 rounds Ã— 3K tokens = 15K tokens              â”‚
    â”‚  â””â”€â”€ Buffer diÃ¡rio: ~140K tokens restantes                     â”‚
    â”‚                                                                 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                                 â”‚
    â”‚  OPENROUTER (x-ai/grok-4.1-fast:free)                          â”‚
    â”‚  â””â”€â”€ 1,000 requests/day (tag :free)                            â”‚
    â”‚                                                                 â”‚
    â”‚  USO PLANEJADO:                                                â”‚
    â”‚  â”œâ”€â”€ AnÃ¡lise profunda: ~3 papers Ã— 5 req = 15 requests         â”‚
    â”‚  â”œâ”€â”€ GeraÃ§Ã£o de post: ~3 variaÃ§Ãµes Ã— 2 req = 6 requests        â”‚
    â”‚  â”œâ”€â”€ Consenso: ~10 rounds Ã— 2 req = 20 requests                â”‚
    â”‚  â””â”€â”€ Buffer diÃ¡rio: ~950 requests restantes                    â”‚
    â”‚                                                                 â”‚
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
    â”‚                                                                 â”‚
    â”‚  RATE LIMITER IMPLEMENTATION                                   â”‚
    â”‚                                                                 â”‚
    â”‚  struct RateLimiter {                                          â”‚
    â”‚      provider: Provider,                                        â”‚
    â”‚      window_requests: AtomicU32,                               â”‚
    â”‚      window_tokens: AtomicU32,                                 â”‚
    â”‚      daily_requests: AtomicU32,                                â”‚
    â”‚      daily_tokens: AtomicU32,                                  â”‚
    â”‚      last_reset: Instant,                                      â”‚
    â”‚  }                                                              â”‚
    â”‚                                                                 â”‚
    â”‚  - Persiste contadores em DuckDB entre execuÃ§Ãµes               â”‚
    â”‚  - Fallback automÃ¡tico: Groq â†’ OpenRouter â†’ Pause              â”‚
    â”‚  - Exponential backoff em 429s                                 â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 Dashboard de Monitoramento

O sistema inclui um dashboard HTML estÃ¡tico gerado a cada execuÃ§Ã£o:

```
                    MONITORING DASHBOARD
                    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                 â”‚
    â”‚  GERADO POR: maud (HTML type-safe em Rust)                     â”‚
    â”‚  LOCALIZAÃ‡ÃƒO: ./dashboard/index.html                            â”‚
    â”‚  ATUALIZAÃ‡ÃƒO: A cada execuÃ§Ã£o do GitHub Actions                â”‚
    â”‚                                                                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  ğŸ“Š RATE LIMIT STATUS                                   â”‚   â”‚
    â”‚  â”‚                                                         â”‚   â”‚
    â”‚  â”‚  GROQ                        OPENROUTER                 â”‚   â”‚
    â”‚  â”‚  â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘ 80%              â–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘ 20%            â”‚   â”‚
    â”‚  â”‚  800/1000 req                200/1000 req               â”‚   â”‚
    â”‚  â”‚  160K/200K tokens            N/A tokens                 â”‚   â”‚
    â”‚  â”‚                                                         â”‚   â”‚
    â”‚  â”‚  Reset: 4h 23m               Reset: 4h 23m              â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  ğŸ“ˆ ÃšLTIMAS 7 EXECUÃ‡Ã•ES                                 â”‚   â”‚
    â”‚  â”‚                                                         â”‚   â”‚
    â”‚  â”‚  Data       Papers  Posts  Aprovados  Erros            â”‚   â”‚
    â”‚  â”‚  Nov 24     12      2      2          0                 â”‚   â”‚
    â”‚  â”‚  Nov 23     15      1      1          0                 â”‚   â”‚
    â”‚  â”‚  Nov 22     8       1      0          1 (rejected)      â”‚   â”‚
    â”‚  â”‚  ...                                                    â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  ğŸ›¡ï¸ SEGURANÃ‡A                                           â”‚   â”‚
    â”‚  â”‚                                                         â”‚   â”‚
    â”‚  â”‚  Prompt Injection Attempts: 0                           â”‚   â”‚
    â”‚  â”‚  Jailbreak Attempts: 0                                  â”‚   â”‚
    â”‚  â”‚  Last Security Scan: Nov 24, 2025 06:00 UTC             â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 5. SeguranÃ§a: ProteÃ§Ã£o contra Jailbreak e Prompt Injection

### 5.1 Arquitetura de Defesa em Camadas

```
                    SECURITY ARCHITECTURE
                    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                 â”‚
    â”‚  LAYER 1: INPUT SANITIZATION                                   â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  - Strip caracteres de controle                         â”‚   â”‚
    â”‚  â”‚  - Normalizar Unicode (NFKC)                            â”‚   â”‚
    â”‚  â”‚  - Detectar padrÃµes de injection conhecidos             â”‚   â”‚
    â”‚  â”‚  - Limitar tamanho de input                             â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â”‚  LAYER 2: PROMPT HARDENING                                     â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  - System prompts imutÃ¡veis (hardcoded)                 â”‚   â”‚
    â”‚  â”‚  - Delimitadores claros para user content               â”‚   â”‚
    â”‚  â”‚  - InstruÃ§Ãµes de role enforcement                       â”‚   â”‚
    â”‚  â”‚  - Output format constraints                            â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â”‚  LAYER 3: OUTPUT VALIDATION                                    â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  - Schema validation (JSON structured output)           â”‚   â”‚
    â”‚  â”‚  - Content policy checks                                â”‚   â”‚
    â”‚  â”‚  - Length bounds verification                           â”‚   â”‚
    â”‚  â”‚  - Blocklist de termos proibidos                        â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â”‚  LAYER 4: BEHAVIORAL MONITORING                                â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  - Log all LLM interactions                             â”‚   â”‚
    â”‚  â”‚  - Anomaly detection em patterns de uso                 â”‚   â”‚
    â”‚  â”‚  - Rate limiting por tipo de operaÃ§Ã£o                   â”‚   â”‚
    â”‚  â”‚  - Human review para outputs suspeitos                  â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 ImplementaÃ§Ã£o de SanitizaÃ§Ã£o

```rust
// Exemplo conceitual de sanitizaÃ§Ã£o em Rust

pub struct InputSanitizer {
    injection_patterns: Vec<Regex>,
    max_length: usize,
}

impl InputSanitizer {
    pub fn sanitize(&self, input: &str) -> Result<String, SecurityError> {
        // 1. Normalize Unicode
        let normalized = input.nfkc().collect::<String>();
        
        // 2. Remove control characters
        let cleaned = normalized.chars()
            .filter(|c| !c.is_control() || *c == '\n')
            .collect::<String>();
        
        // 3. Check length
        if cleaned.len() > self.max_length {
            return Err(SecurityError::InputTooLong);
        }
        
        // 4. Check for injection patterns
        for pattern in &self.injection_patterns {
            if pattern.is_match(&cleaned) {
                log::warn!("Injection pattern detected: {}", pattern);
                return Err(SecurityError::InjectionDetected);
            }
        }
        
        Ok(cleaned)
    }
}
```

---

## 6. Estrutura do Projeto

### 6.1 Ãrvore de DiretÃ³rios

```
arxiv-linkedin-agent/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ daily-scan.yml          # Workflow principal (6x/dia)
â”‚       â”œâ”€â”€ approval-check.yml      # Verifica aprovaÃ§Ãµes Telegram
â”‚       â”œâ”€â”€ publish.yml             # Publica posts aprovados
â”‚       â””â”€â”€ backup.yml              # Backup semanal do DuckDB
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.rs                     # Entry point
â”‚   â”‚
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ scout.rs                # Agente de ingestÃ£o Arxiv
â”‚   â”‚   â”œâ”€â”€ analyst.rs              # Agente cognitivo
â”‚   â”‚   â”œâ”€â”€ scribe.rs               # Agente de escrita
â”‚   â”‚   â”œâ”€â”€ guardian.rs             # Agente de conformidade Shabbat
â”‚   â”‚   â””â”€â”€ liaison.rs              # Agente de interface Telegram
â”‚   â”‚
â”‚   â”œâ”€â”€ consensus/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ pbft.rs                 # Protocolo de consenso
â”‚   â”‚   â””â”€â”€ merger.rs               # Merge de propostas
â”‚   â”‚
â”‚   â”œâ”€â”€ memory/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ duckdb.rs               # Interface DuckDB
â”‚   â”‚   â”œâ”€â”€ lancedb.rs              # Interface LanceDB
â”‚   â”‚   â”œâ”€â”€ context_manager.rs      # Gerenciador de janela de contexto
â”‚   â”‚   â””â”€â”€ embeddings.rs           # GeraÃ§Ã£o de embeddings
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ provider.rs             # Trait para providers
â”‚   â”‚   â”œâ”€â”€ groq.rs                 # Cliente Groq
â”‚   â”‚   â”œâ”€â”€ openrouter.rs           # Cliente OpenRouter
â”‚   â”‚   â””â”€â”€ rate_limiter.rs         # Rate limiting
â”‚   â”‚
â”‚   â”œâ”€â”€ integrations/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ arxiv.rs                # Cliente API Arxiv
â”‚   â”‚   â”œâ”€â”€ linkedin.rs             # Cliente API LinkedIn
â”‚   â”‚   â””â”€â”€ telegram.rs             # Bot Telegram
â”‚   â”‚
â”‚   â”œâ”€â”€ security/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ sanitizer.rs            # SanitizaÃ§Ã£o de input
â”‚   â”‚   â”œâ”€â”€ prompt_guard.rs         # ProteÃ§Ã£o de prompts
â”‚   â”‚   â””â”€â”€ output_validator.rs     # ValidaÃ§Ã£o de output
â”‚   â”‚
â”‚   â”œâ”€â”€ observability/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â”œâ”€â”€ tracing.rs              # Distributed tracing
â”‚   â”‚   â”œâ”€â”€ metrics.rs              # MÃ©tricas de execuÃ§Ã£o
â”‚   â”‚   â””â”€â”€ dashboard.rs            # Gerador de dashboard HTML
â”‚   â”‚
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ mod.rs
â”‚   â”‚   â””â”€â”€ settings.rs             # ConfiguraÃ§Ãµes tipadas
â”‚   â”‚
â”‚   â””â”€â”€ utils/
â”‚       â”œâ”€â”€ mod.rs
â”‚       â”œâ”€â”€ pdf_parser.rs           # Parser de PDFs
â”‚       â””â”€â”€ text_chunker.rs         # Chunking de texto
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ memory.duckdb               # Banco principal (gitignore)
â”‚   â”œâ”€â”€ embeddings/                 # Ãndices LanceDB (gitignore)
â”‚   â””â”€â”€ style_examples/             # Posts de exemplo do usuÃ¡rio
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ index.html                  # Dashboard estÃ¡tico gerado
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ topics.toml                 # TÃ³picos de interesse configurÃ¡veis
â”‚   â”œâ”€â”€ prompts.toml                # Prompts do sistema
â”‚   â””â”€â”€ linkedin_profiles.toml      # Perfis LinkedIn configurados
â”‚
â”œâ”€â”€ Cargo.toml
â”œâ”€â”€ Cargo.lock
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE (MIT)
â””â”€â”€ .env.example
```

### 6.2 DependÃªncias (Cargo.toml)

```toml
[package]
name = "arxiv-linkedin-agent"
version = "0.1.0"
edition = "2024"
rust-version = "1.82"
license = "MIT"
description = "Multi-agent system for AI paper curation and LinkedIn publishing"
repository = "https://github.com/SamoraDC/arxiv-linkedin-agent"
authors = ["Davi Samora <samora.davi@gmail.com>"]

[dependencies]
# Async Runtime
tokio = { version = "1.40", features = ["full"] }

# LLM & AI
rig-core = "0.6"              # OrquestraÃ§Ã£o de agentes
async-openai = "0.25"         # Cliente OpenAI-compatible (Groq/OpenRouter)
fastembed = "4.0"             # Embeddings locais

# Databases
duckdb = { version = "1.4", features = ["bundled", "json", "parquet"] }
lancedb = "0.15"              # Vector database
arrow = "53"                  # Apache Arrow

# HTTP & APIs
reqwest = { version = "0.12", features = ["json", "cookies", "gzip"] }
serde = { version = "1.0", features = ["derive"] }
serde_json = "1.0"
serde_xml_rs = "0.6"          # Parser Arxiv XML

# Telegram
teloxide = { version = "0.14", features = ["macros", "auto-send"] }

# Date/Time & Astronomy
chrono = { version = "0.4", features = ["serde"] }
sunrise = "1.2"               # CÃ¡lculo de Shabbat

# HTML Generation
maud = "0.26"                 # HTML type-safe

# Observability
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }
opentelemetry = "0.27"
metrics = "0.24"

# Security
regex = "1.10"
unicode-normalization = "0.1"

# Utils
anyhow = "1.0"
thiserror = "2.0"
config = "0.14"
toml = "0.8"
uuid = { version = "1.10", features = ["v4", "serde"] }
base64 = "0.22"

# PDF Processing
pdf-extract = "0.7"
lopdf = "0.34"

[dev-dependencies]
tokio-test = "0.4"
mockall = "0.13"
proptest = "1.5"

[profile.release]
opt-level = 3
lto = true
codegen-units = 1
strip = true
```

---

## 7. GitHub Actions Workflows

### 7.1 Workflow Principal (daily-scan.yml)

```yaml
name: Daily ArXiv Scan

on:
  schedule:
    # Executa 4x por dia (exceto sexta 18h - sÃ¡bado 18h, verificado no cÃ³digo)
    - cron: '0 6,12,18,0 * * *'
  workflow_dispatch:
    inputs:
      force_run:
        description: 'Force run even during Shabbat'
        required: false
        default: 'false'

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  scan-and-process:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Setup Rust
        uses: dtolnay/rust-action@stable
        with:
          toolchain: stable
          components: clippy
          
      - name: Cache Cargo
        uses: actions/cache@v4
        with:
          path: |
            ~/.cargo/bin/
            ~/.cargo/registry/index/
            ~/.cargo/registry/cache/
            ~/.cargo/git/db/
            target/
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          
      - name: Download Data Artifacts
        uses: actions/download-artifact@v4
        with:
          name: agent-data
          path: data/
        continue-on-error: true  # First run won't have artifacts
        
      - name: Build Release Binary
        run: cargo build --release
        
      - name: Run Agent
        env:
          GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }}
          OPENROUTER_API_KEY: ${{ secrets.OPENROUTER_API_KEY }}
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
          LINKEDIN_ACCESS_TOKEN: ${{ secrets.LINKEDIN_ACCESS_TOKEN }}
          LINKEDIN_PERSON_URN: ${{ secrets.LINKEDIN_PERSON_URN }}
          USER_LATITUDE: ${{ secrets.USER_LATITUDE }}
          USER_LONGITUDE: ${{ secrets.USER_LONGITUDE }}
        run: ./target/release/arxiv-linkedin-agent scan
        
      - name: Upload Data Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: agent-data
          path: |
            data/memory.duckdb
            data/embeddings/
          retention-days: 90
          
      - name: Upload Dashboard
        uses: actions/upload-pages-artifact@v3
        with:
          path: dashboard/
          
      - name: Commit Dashboard Updates
        run: |
          git config user.name 'ArxivAgent Bot'
          git config user.email 'bot@arxivagent.local'
          git add dashboard/
          git diff --staged --quiet || git commit -m "ğŸ“Š Update dashboard $(date +%Y-%m-%d)"
          git push
```

### 7.2 Workflow de AprovaÃ§Ã£o (approval-check.yml)

```yaml
name: Check Telegram Approvals

on:
  schedule:
    - cron: '*/15 * * * *'  # A cada 15 minutos
  workflow_dispatch:

jobs:
  check-approvals:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Download Data
        uses: actions/download-artifact@v4
        with:
          name: agent-data
          path: data/
          
      - name: Setup Rust
        uses: dtolnay/rust-action@stable
        
      - name: Build
        run: cargo build --release
        
      - name: Check Approvals
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: ./target/release/arxiv-linkedin-agent check-approvals
        
      - name: Upload Updated Data
        uses: actions/upload-artifact@v4
        with:
          name: agent-data
          path: data/
```

### 7.3 Workflow de PublicaÃ§Ã£o (publish.yml)

```yaml
name: Publish Approved Posts

on:
  workflow_run:
    workflows: ["Check Telegram Approvals"]
    types: [completed]

jobs:
  publish:
    if: ${{ github.event.workflow_run.conclusion == 'success' }}
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Download Data
        uses: actions/download-artifact@v4
        with:
          name: agent-data
          path: data/
          
      - name: Setup Rust
        uses: dtolnay/rust-action@stable
        
      - name: Build
        run: cargo build --release
        
      - name: Publish to LinkedIn
        env:
          LINKEDIN_ACCESS_TOKEN: ${{ secrets.LINKEDIN_ACCESS_TOKEN }}
          LINKEDIN_PERSON_URN: ${{ secrets.LINKEDIN_PERSON_URN }}
          USER_LATITUDE: ${{ secrets.USER_LATITUDE }}
          USER_LONGITUDE: ${{ secrets.USER_LONGITUDE }}
        run: ./target/release/arxiv-linkedin-agent publish
        
      - name: Notify Success
        env:
          TELEGRAM_BOT_TOKEN: ${{ secrets.TELEGRAM_BOT_TOKEN }}
          TELEGRAM_CHAT_ID: ${{ secrets.TELEGRAM_CHAT_ID }}
        run: ./target/release/arxiv-linkedin-agent notify-success
```

---

## 8. Schemas do Banco de Dados

### 8.1 DuckDB Schema

```sql
-- Tabela principal de papers processados
CREATE TABLE papers (
    id VARCHAR PRIMARY KEY,           -- arxiv_id (e.g., "2505.12345")
    title VARCHAR NOT NULL,
    abstract TEXT NOT NULL,
    authors JSON NOT NULL,            -- ["Author 1", "Author 2"]
    categories JSON NOT NULL,         -- ["cs.AI", "cs.LG"]
    published_date DATE NOT NULL,
    pdf_url VARCHAR,
    source_url VARCHAR NOT NULL,
    
    -- Processamento
    processed_at TIMESTAMP NOT NULL,
    relevance_score FLOAT,            -- 0-10
    priority VARCHAR,                 -- 'normal', 'high', 'critical'
    
    -- Estado
    status VARCHAR NOT NULL,          -- 'filtered', 'analyzed', 'posted', 'skipped'
    
    -- Metadados
    full_text_extracted BOOLEAN DEFAULT FALSE,
    page_count INTEGER,
    
    UNIQUE(id)
);

-- Posts gerados
CREATE TABLE posts (
    id UUID PRIMARY KEY,
    paper_id VARCHAR REFERENCES papers(id),
    
    -- ConteÃºdo
    content TEXT NOT NULL,
    variation_id INTEGER DEFAULT 1,   -- Para A/B testing
    series_id UUID,                   -- Para posts em sÃ©rie (Pt 1, Pt 2...)
    series_part INTEGER,
    
    -- GeraÃ§Ã£o
    generated_at TIMESTAMP NOT NULL,
    generator_model VARCHAR,          -- 'groq/gpt-oss-120b', 'openrouter/grok-4.1'
    consensus_score FLOAT,            -- ConcordÃ¢ncia entre LLMs
    
    -- AprovaÃ§Ã£o
    status VARCHAR NOT NULL,          -- 'pending', 'approved', 'rejected', 'published'
    sent_for_approval_at TIMESTAMP,
    approved_at TIMESTAMP,
    rejection_reason TEXT,
    
    -- PublicaÃ§Ã£o
    published_at TIMESTAMP,
    linkedin_post_urn VARCHAR,
    
    -- Analytics (preenchido apÃ³s publicaÃ§Ã£o)
    likes_count INTEGER DEFAULT 0,
    comments_count INTEGER DEFAULT 0,
    shares_count INTEGER DEFAULT 0,
    views_count INTEGER DEFAULT 0,
    engagement_rate FLOAT
);

-- Feedback do usuÃ¡rio (Reasoning Bank)
CREATE TABLE feedback (
    id UUID PRIMARY KEY,
    post_id UUID REFERENCES posts(id),
    feedback_type VARCHAR NOT NULL,   -- 'approve', 'reject', 'edit'
    feedback_text TEXT,
    received_at TIMESTAMP NOT NULL
);

-- SessÃµes de execuÃ§Ã£o (Episodic Memory)
CREATE TABLE sessions (
    id UUID PRIMARY KEY,
    started_at TIMESTAMP NOT NULL,
    ended_at TIMESTAMP,
    
    -- MÃ©tricas
    papers_scanned INTEGER DEFAULT 0,
    papers_filtered INTEGER DEFAULT 0,
    papers_analyzed INTEGER DEFAULT 0,
    posts_generated INTEGER DEFAULT 0,
    
    -- Rate limits
    groq_requests_used INTEGER DEFAULT 0,
    groq_tokens_used INTEGER DEFAULT 0,
    openrouter_requests_used INTEGER DEFAULT 0,
    
    -- Erros
    errors JSON,
    
    -- Status
    status VARCHAR NOT NULL           -- 'running', 'completed', 'failed'
);

-- Exemplos de estilo do usuÃ¡rio
CREATE TABLE style_examples (
    id UUID PRIMARY KEY,
    content TEXT NOT NULL,
    source VARCHAR,                   -- 'linkedin', 'manual'
    added_at TIMESTAMP NOT NULL,
    engagement_score FLOAT,           -- Para priorizar exemplos de sucesso
    
    -- Embedding Ã© armazenado no LanceDB
    embedding_id VARCHAR
);

-- Rate limits persistidos
CREATE TABLE rate_limits (
    provider VARCHAR PRIMARY KEY,     -- 'groq', 'openrouter'
    requests_used INTEGER DEFAULT 0,
    tokens_used INTEGER DEFAULT 0,
    last_reset TIMESTAMP NOT NULL,
    
    -- HistÃ³rico
    daily_history JSON                -- Ãšltimos 7 dias
);

-- ConfiguraÃ§Ãµes dinÃ¢micas
CREATE TABLE config (
    key VARCHAR PRIMARY KEY,
    value JSON NOT NULL,
    updated_at TIMESTAMP NOT NULL
);
```

### 8.2 LanceDB Schema (Vector Store)

```python
# Conceitual - implementado em Rust via lancedb crate

# Tabela de embeddings de papers
paper_embeddings = {
    "paper_id": str,           # FK para DuckDB
    "vector": Vector(384),     # fastembed output dimension
    "text_chunk": str,         # Texto original do chunk
    "chunk_type": str,         # 'abstract', 'introduction', 'methodology', etc.
    "chunk_index": int
}

# Tabela de embeddings de estilo
style_embeddings = {
    "example_id": str,         # FK para DuckDB
    "vector": Vector(384),
    "text": str
}

# Tabela de embeddings de insights
insight_embeddings = {
    "insight_id": str,
    "paper_id": str,
    "vector": Vector(384),
    "insight_text": str,
    "quality_score": float     # Baseado em feedback
}
```

---

## 9. Interface de ConfiguraÃ§Ã£o

### 9.1 Arquivo de TÃ³picos (config/topics.toml)

```toml
[topics]
# TÃ³picos primÃ¡rios (sempre buscados)
primary = [
    "reinforcement learning",
    "multi-agent systems",
    "RAG retrieval augmented generation",
    "R3 retrieval reasoning reinforcement",
    "AlphaEvolve",
    "Absolute Zero",
    "context engineering",
    "prompt engineering",
    "agentic AI",
    "LLM agents"
]

# TÃ³picos secundÃ¡rios (buscados se houver quota)
secondary = [
    "machine learning",
    "deep learning",
    "neural networks",
    "transformer architectures",
    "self-play",
    "RLHF",
    "DPO",
    "chain of thought",
    "reasoning",
    "code generation"
]

# TÃ³picos de exclusÃ£o
exclude = [
    "biology",
    "chemistry",
    "physics",
    "medical"
]

[arxiv]
# Categorias do Arxiv a monitorar
categories = ["cs.AI", "cs.LG", "cs.CL", "cs.MA", "cs.NE"]

# MÃ¡ximo de papers por dia
max_papers_per_day = 50

# MÃ¡ximo de papers a analisar profundamente
max_deep_analysis = 5

[detection]
# PadrÃµes para detectar papers disruptivos
disruptive_patterns = [
    { name = "AlphaEvolve", keywords = ["evolutionary", "code generation", "automated discovery"] },
    { name = "Absolute Zero", keywords = ["zero data", "self-play reasoning", "no training data"] },
    { name = "Novel Architecture", keywords = ["new architecture", "breakthrough", "state-of-the-art"] }
]
```

### 9.2 Arquivo de Perfis LinkedIn (config/linkedin_profiles.toml)

```toml
# Perfis configurÃ¡veis para diferentes usuÃ¡rios

[[profiles]]
name = "default"
person_urn = "${LINKEDIN_PERSON_URN}"  # VariÃ¡vel de ambiente
access_token = "${LINKEDIN_ACCESS_TOKEN}"

# PreferÃªncias de estilo
style = """
Profissional mas acessÃ­vel
ParÃ¡grafos curtos
Uso moderado de emojis
Foco em insights prÃ¡ticos
ConexÃµes com indÃºstria
"""

# HorÃ¡rios preferenciais de postagem
preferred_hours = [9, 12, 18]

# Hashtags padrÃ£o
default_hashtags = ["#AI", "#MachineLearning", "#DataScience", "#Tech"]

[[profiles]]
name = "secondary"
# Pode ter outro perfil configurado
```

### 9.3 Interface de Setup Inicial

O sistema inclui um comando de setup interativo:

```bash
$ ./arxiv-linkedin-agent setup

ğŸš€ ArxivAgent Setup Wizard

ğŸ“ Step 1/5: API Keys
   Enter your Groq API Key: ********
   âœ… Groq API verified (model: openai/gpt-oss-120b available)
   
   Enter your OpenRouter API Key: ********
   âœ… OpenRouter API verified (model: x-ai/grok-4.1-fast:free available)

ğŸ“± Step 2/5: Telegram Bot
   Enter your Telegram Bot Token: ********
   âœ… Bot verified (@YourBotName)
   
   Enter your Telegram Chat ID: ********
   âœ… Chat access verified

ğŸ’¼ Step 3/5: LinkedIn
   Follow these steps to get your LinkedIn access:
   1. Go to https://www.linkedin.com/developers/apps
   2. Create a new app
   3. Request 'Share on LinkedIn' permission
   4. Generate access token
   
   Enter your LinkedIn Access Token: ********
   âœ… LinkedIn API verified
   
   Enter your LinkedIn Person URN (from profile): ********
   âœ… Profile access verified

ğŸ“ Step 4/5: Location (for Shabbat calculation)
   Enter your latitude (e.g., -22.9068): -22.9068
   Enter your longitude (e.g., -43.1729): -43.1729
   âœ… Location: Campinas, SP, Brazil

ğŸ“ Step 5/5: Style Examples
   Would you like to import your recent LinkedIn posts? (y/n): y
   âœ… Imported 15 posts as style examples

âœ¨ Setup complete! Your secrets have been saved to .env
   
   Next steps:
   1. Add secrets to GitHub repository settings
   2. Run: ./arxiv-linkedin-agent test
   3. Enable GitHub Actions workflows
```

---

## 10. Observabilidade e Rastreabilidade

### 10.1 Arquitetura de Tracing

```
                    OBSERVABILITY STACK
                    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                 â”‚
    â”‚  APPLICATION LAYER                                              â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚                     tracing crate                        â”‚   â”‚
    â”‚  â”‚                                                          â”‚   â”‚
    â”‚  â”‚  #[instrument(skip(self), fields(paper_id = %paper.id))] â”‚   â”‚
    â”‚  â”‚  async fn analyze_paper(&self, paper: &Paper) { ... }    â”‚   â”‚
    â”‚  â”‚                                                          â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â–¼                                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚              tracing-subscriber                          â”‚   â”‚
    â”‚  â”‚                                                          â”‚   â”‚
    â”‚  â”‚  - JSON formatted logs                                   â”‚   â”‚
    â”‚  â”‚  - Structured fields (paper_id, agent, model, etc.)     â”‚   â”‚
    â”‚  â”‚  - Span timing                                           â”‚   â”‚
    â”‚  â”‚  - Error context                                         â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â–¼                                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚                    OUTPUTS                               â”‚   â”‚
    â”‚  â”‚                                                          â”‚   â”‚
    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚   â”‚
    â”‚  â”‚  â”‚  STDOUT  â”‚  â”‚  DuckDB  â”‚  â”‚Dashboard â”‚              â”‚   â”‚
    â”‚  â”‚  â”‚  (JSON)  â”‚  â”‚  (logs)  â”‚  â”‚  (HTML)  â”‚              â”‚   â”‚
    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚   â”‚
    â”‚  â”‚       â”‚              â”‚              â”‚                    â”‚   â”‚
    â”‚  â”‚       â–¼              â–¼              â–¼                    â”‚   â”‚
    â”‚  â”‚  GH Actions     Queries SQL    GitHub Pages             â”‚   â”‚
    â”‚  â”‚    Logs                                                  â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 10.2 MÃ©tricas Coletadas

```rust
// MÃ©tricas estruturadas registradas a cada execuÃ§Ã£o

pub struct ExecutionMetrics {
    // Timing
    pub total_duration_ms: u64,
    pub arxiv_fetch_ms: u64,
    pub llm_processing_ms: u64,
    pub embedding_generation_ms: u64,
    
    // Volumes
    pub papers_fetched: u32,
    pub papers_filtered_heuristic: u32,
    pub papers_filtered_semantic: u32,
    pub papers_analyzed: u32,
    pub posts_generated: u32,
    
    // API Usage
    pub groq_requests: u32,
    pub groq_tokens_input: u32,
    pub groq_tokens_output: u32,
    pub openrouter_requests: u32,
    
    // Quality
    pub average_relevance_score: f32,
    pub consensus_agreement_rate: f32,
    
    // Errors
    pub api_errors: u32,
    pub retry_count: u32,
    pub rate_limit_hits: u32,
}
```

---

## 11. Backup e Disaster Recovery

### 11.1 EstratÃ©gia de Backup

```
                    BACKUP ARCHITECTURE
                    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                 â”‚
    â”‚  PRIMARY STORAGE                                                â”‚
    â”‚  â”œâ”€â”€ GitHub Artifacts (90 days retention)                      â”‚
    â”‚  â”‚   â””â”€â”€ data/memory.duckdb                                    â”‚
    â”‚  â”‚   â””â”€â”€ data/embeddings/                                      â”‚
    â”‚  â”‚                                                              â”‚
    â”‚  SECONDARY BACKUP (Weekly)                                      â”‚
    â”‚  â”œâ”€â”€ Google Drive (via rclone)                                 â”‚
    â”‚  â”‚   â””â”€â”€ arxiv-agent-backup-YYYY-MM-DD.tar.gz                 â”‚
    â”‚  â”‚                                                              â”‚
    â”‚  CLEANUP POLICY                                                 â”‚
    â”‚  â”œâ”€â”€ Remove embeddings de papers > 6 meses                     â”‚
    â”‚  â”œâ”€â”€ Manter tÃ­tulos de todos os papers (deduplicaÃ§Ã£o)         â”‚
    â”‚  â”œâ”€â”€ Comprimir logs > 30 dias                                  â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 11.2 Workflow de Backup (backup.yml)

```yaml
name: Weekly Backup

on:
  schedule:
    - cron: '0 3 * * 0'  # Domingos Ã s 3h
  workflow_dispatch:

jobs:
  backup:
    runs-on: ubuntu-latest
    
    steps:
      - name: Download Data
        uses: actions/download-artifact@v4
        with:
          name: agent-data
          path: data/
          
      - name: Setup rclone
        uses: animosity22/gclone-action@v1
        
      - name: Configure rclone
        run: |
          mkdir -p ~/.config/rclone
          echo "${{ secrets.RCLONE_CONFIG }}" > ~/.config/rclone/rclone.conf
          
      - name: Create Backup Archive
        run: |
          DATE=$(date +%Y-%m-%d)
          tar -czvf backup-$DATE.tar.gz data/
          
      - name: Upload to Google Drive
        run: |
          rclone copy backup-*.tar.gz gdrive:arxiv-agent-backups/
          
      - name: Cleanup Old Backups
        run: |
          # Manter apenas Ãºltimos 4 backups
          rclone delete gdrive:arxiv-agent-backups/ --min-age 30d
```

---

## 12. A/B Testing e Analytics

### 12.1 Sistema de VariaÃ§Ãµes

```
                    A/B TESTING FLOW
                    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                 â”‚
    â”‚  GERAÃ‡ÃƒO DE VARIAÃ‡Ã•ES                                          â”‚
    â”‚                                                                 â”‚
    â”‚  Paper Selecionado                                              â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â–¼                                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
    â”‚  â”‚   Scribe    â”‚                                               â”‚
    â”‚  â”‚   Agent     â”‚                                               â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
    â”‚         â–¼              â–¼              â–¼                        â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
    â”‚  â”‚Variation Aâ”‚  â”‚Variation Bâ”‚  â”‚Variation Câ”‚                  â”‚
    â”‚  â”‚(TÃ©cnico)  â”‚  â”‚(Storytell)â”‚  â”‚(Provocativo)                â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
    â”‚         â”‚              â”‚              â”‚                        â”‚
    â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
    â”‚                        â–¼                                        â”‚
    â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
    â”‚                 â”‚   Ranking   â”‚                                 â”‚
    â”‚                 â”‚  Internal   â”‚                                 â”‚
    â”‚                 â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
    â”‚                        â”‚                                        â”‚
    â”‚                        â–¼                                        â”‚
    â”‚                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â”‚
    â”‚                 â”‚   Telegram  â”‚  "Qual variaÃ§Ã£o prefere?"      â”‚
    â”‚                 â”‚   Choice    â”‚  [A] [B] [C]                   â”‚
    â”‚                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                 â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 12.2 Coleta de Analytics (PÃ³s-PublicaÃ§Ã£o)

```
                    ENGAGEMENT TRACKING
                    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                 â”‚
    â”‚  POST PUBLICADO                                                 â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â–¼                                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
    â”‚  â”‚  LinkedIn   â”‚  URN: urn:li:share:1234567890                 â”‚
    â”‚  â”‚  Post URN   â”‚                                               â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â”‚  (24h depois)                                        â”‚
    â”‚         â–¼                                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                               â”‚
    â”‚  â”‚  Analytics  â”‚  GET /socialActions/{urn}/metadata            â”‚
    â”‚  â”‚  API Call   â”‚                                               â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜                                               â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â–¼                                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  MÃ‰TRICAS COLETADAS                                     â”‚   â”‚
    â”‚  â”‚                                                         â”‚   â”‚
    â”‚  â”‚  - likes_count                                          â”‚   â”‚
    â”‚  â”‚  - comments_count                                       â”‚   â”‚
    â”‚  â”‚  - shares_count                                         â”‚   â”‚
    â”‚  â”‚  - impressions (se disponÃ­vel)                          â”‚   â”‚
    â”‚  â”‚  - engagement_rate = (likes+comments+shares)/impressionsâ”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚         â”‚                                                       â”‚
    â”‚         â–¼                                                       â”‚
    â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
    â”‚  â”‚  REINFORCEMENT LEARNING SIGNAL                          â”‚   â”‚
    â”‚  â”‚                                                         â”‚   â”‚
    â”‚  â”‚  - Update style_examples with engagement scores         â”‚   â”‚
    â”‚  â”‚  - Priorizar variaÃ§Ãµes com alto engagement              â”‚   â”‚
    â”‚  â”‚  - Ajustar prompts do Scribe baseado em feedback        â”‚   â”‚
    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 13. Roadmap de ImplementaÃ§Ã£o

### Fase 1: Core Infrastructure (Semanas 1-2)

```
â–¡ Setup inicial do projeto Rust
â–¡ Implementar cliente Arxiv API (parsing XML)
â–¡ Implementar cliente DuckDB (schema inicial)
â–¡ Implementar cliente Groq (async-openai)
â–¡ Implementar cliente OpenRouter
â–¡ Rate limiter bÃ¡sico
â–¡ Testes unitÃ¡rios de cada componente
```

### Fase 2: Agents & Memory (Semanas 3-4)

```
â–¡ Implementar Scout Agent (filtragem heurÃ­stica + semÃ¢ntica)
â–¡ Implementar sistema de embeddings (fastembed)
â–¡ Integrar LanceDB para busca vetorial
â–¡ Implementar Context Window Manager
â–¡ Implementar Analyst Agent (anÃ¡lise de papers)
â–¡ Implementar lÃ³gica de chunking hierÃ¡rquico
â–¡ Testes de integraÃ§Ã£o
```

### Fase 3: Consensus & Creation (Semanas 5-6)

```
â–¡ Implementar Consensus Engine (PBFT simplificado)
â–¡ Implementar Scribe Agent (geraÃ§Ã£o de posts)
â–¡ Implementar sistema de variaÃ§Ãµes A/B
â–¡ Implementar Few-Shot Learning com exemplos
â–¡ Guardian Agent (cÃ¡lculo de Shabbat)
â–¡ Testes end-to-end do pipeline
```

### Fase 4: Human Interface (Semanas 7-8)

```
â–¡ Bot Telegram (teloxide)
â–¡ Workflow de aprovaÃ§Ã£o assÃ­ncrono
â–¡ Inline keyboards para escolha de variaÃ§Ãµes
â–¡ Feedback loop implementation
â–¡ Cliente LinkedIn API
â–¡ PublicaÃ§Ã£o automÃ¡tica
```

### Fase 5: Observability & Security (Semana 9)

```
â–¡ Tracing distribuÃ­do
â–¡ Dashboard HTML (maud)
â–¡ SanitizaÃ§Ã£o de inputs
â–¡ Prompt hardening
â–¡ Output validation
â–¡ Security tests
```

### Fase 6: Deployment & Polish (Semana 10)

```
â–¡ GitHub Actions workflows
â–¡ Backup automation
â–¡ Analytics collection
â–¡ Setup wizard
â–¡ DocumentaÃ§Ã£o completa
â–¡ Release v1.0.0
```

---

## 14. Estimativa de Custos

```
                    CUSTO MENSAL ESTIMADO
                    
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                                                                 â”‚
    â”‚  COMPONENTE                              CUSTO                  â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
    â”‚                                                                 â”‚
    â”‚  GitHub Actions                          $0.00                  â”‚
    â”‚  (2000 min/mÃªs free tier)                                      â”‚
    â”‚                                                                 â”‚
    â”‚  Groq API                                $0.00                  â”‚
    â”‚  (Free tier: 200K tokens/dia)                                  â”‚
    â”‚                                                                 â”‚
    â”‚  OpenRouter                              $0.00                  â”‚
    â”‚  (1000 req/dia com tag :free)                                  â”‚
    â”‚                                                                 â”‚
    â”‚  LinkedIn API                            $0.00                  â”‚
    â”‚  (Free para posts pessoais)                                    â”‚
    â”‚                                                                 â”‚
    â”‚  Telegram Bot                            $0.00                  â”‚
    â”‚  (Gratuito)                                                    â”‚
    â”‚                                                                 â”‚
    â”‚  Storage (GitHub Artifacts)              $0.00                  â”‚
    â”‚  (500MB free)                                                   â”‚
    â”‚                                                                 â”‚
    â”‚  Google Drive Backup                     $0.00                  â”‚
    â”‚  (15GB free)                                                    â”‚
    â”‚                                                                 â”‚
    â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
    â”‚  TOTAL MENSAL                            $0.00                  â”‚
    â”‚                                                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 15. ConsideraÃ§Ãµes Finais

Este projeto representa uma implementaÃ§Ã£o completa de um sistema multi-agente para curadoria automatizada de conhecimento cientÃ­fico. Os diferenciais principais sÃ£o:

1. **100% Rust**: Performance, seguranÃ§a e confiabilidade em ambiente serverless
2. **Custo Zero**: Opera inteiramente dentro de free tiers
3. **Consenso Multi-LLM**: Qualidade garantida por acordo entre modelos
4. **Engenharia de Contexto**: MemÃ³ria de longo prazo para papers extensos
5. **Human-in-the-Loop**: Controle total sobre publicaÃ§Ãµes via Telegram
6. **Conformidade Religiosa**: Respeito automÃ¡tico ao Shabbat
7. **Observabilidade**: Rastreabilidade completa de ponta a ponta
8. **SeguranÃ§a**: ProteÃ§Ã£o contra prompt injection e jailbreak

O sistema estÃ¡ pronto para ser desenvolvido iterativamente, comeÃ§ando pela infraestrutura core e evoluindo atÃ© um produto completo e polido.
